{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOszegMHKZ6bRE7Y8+cZdgI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexeyK12/Implementation-of-the-article-StyleGAN-NADA/blob/main/app_StyleGAN_NADA_AK_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# УСТАНОВКА ЗАВИСИМОСТЕЙ\n",
        "#########################\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "#!pip uninstall google-genai -y\n",
        "#!pip install gradio\n",
        "\n",
        "import os\n",
        "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"7.5\"\n",
        "\n",
        "!apt-get -y install ninja-build\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install gradio==3.39.0\n",
        "\n",
        "if not os.path.exists(\"Article-implementation-StyleGAN-NADA\"):\n",
        "    !git clone https://github.com/AlexeyK12/Article-implementation-StyleGAN-NADA.git\n",
        "\n",
        "if not os.path.exists(\"stylegan2-ffhq-config-f.pt\"):\n",
        "    !wget https://huggingface.co/akhaliq/OneshotCLIP-stylegan2-ffhq/resolve/main/stylegan2-ffhq-config-f.pt -O stylegan2-ffhq-config-f.pt\n",
        "\n",
        "%cd Article-implementation-StyleGAN-NADA\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from model import Generator\n",
        "import clip\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "outdir = \"/content/outputs_nada_colab\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################\n",
        "# ИНИЦИАЛИЗАЦИЯ ФУНКЦИЙ\n",
        "########################\n",
        "\n",
        "# загрузка CLIP\n",
        "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
        "clip_model.eval().requires_grad_(False)\n",
        "\n",
        "# загрузка StyleGAN2\n",
        "ckpt_path_base = \"/content/stylegan2-ffhq-config-f.pt\"\n",
        "\n",
        "latent_dim = 512\n",
        "image_size = 1024\n",
        "\n",
        "base_generator = Generator(\n",
        "    size=image_size,\n",
        "    style_dim=latent_dim,\n",
        "    n_mlp=8,\n",
        "    channel_multiplier=2\n",
        ").to(device)\n",
        "\n",
        "ckpt = torch.load(ckpt_path_base, map_location=device)\n",
        "base_generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
        "\n",
        "def copy_generator(src_gen):\n",
        "    import copy\n",
        "    new_gen = Generator(\n",
        "    size=image_size,\n",
        "    style_dim=latent_dim,\n",
        "    n_mlp=8,\n",
        "    channel_multiplier=2\n",
        "    ).to(device)\n",
        "\n",
        "    new_gen.load_state_dict(src_gen.state_dict(), strict=False)\n",
        "    return new_gen\n",
        "\n",
        "# заморозка coarse-слоёв\n",
        "def freeze_layers(g, freeze_num=2):\n",
        "    blocks_to_freeze = freeze_num * 2\n",
        "    for i, conv_block in enumerate(g.convs):\n",
        "        if i < blocks_to_freeze:\n",
        "            for param in conv_block.parameters():\n",
        "                param.requires_grad = False\n",
        "    for i, to_rgb_layer in enumerate(g.to_rgbs):\n",
        "        if i < freeze_num:\n",
        "            for param in to_rgb_layer.parameters():\n",
        "                param.requires_grad = False\n",
        "    return g\n",
        "\n",
        "# предобработка для CLIP\n",
        "def clip_preprocess_tensor(imgs):\n",
        "    imgs = (imgs.clamp(-1,1) + 1)/2\n",
        "    imgs_224 = F.interpolate(imgs, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "    clip_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=device).view(1, -1, 1, 1)\n",
        "    clip_std  = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=device).view(1, -1, 1, 1)\n",
        "    imgs_224 = (imgs_224 - clip_mean) / clip_std\n",
        "    return imgs_224\n",
        "\n",
        "# сохранение модели\n",
        "def save_checkpoint(gen, path):\n",
        "    torch.save({\"g_ema\": gen.state_dict()}, path)\n",
        "\n",
        "# функция обучения\n",
        "def train_model(\n",
        "    freeze_until=1,\n",
        "    steps=500,\n",
        "    batch_size=2,\n",
        "    lr=1e-4,\n",
        "    prompt_target=\"joker\"\n",
        "):\n",
        "    generator = copy_generator(base_generator)\n",
        "    generator.train()\n",
        "\n",
        "    # замораживаем слои\n",
        "    generator = freeze_layers(generator, freeze_num=freeze_until)\n",
        "\n",
        "    # текстовые эмбеддинги\n",
        "    prompt_orig = \"face\"\n",
        "    text_orig_emb = clip_model.encode_text(clip.tokenize(prompt_orig).to(device))\n",
        "    text_target_emb = clip_model.encode_text(clip.tokenize(prompt_target).to(device))\n",
        "    text_orig_emb   = text_orig_emb / text_orig_emb.norm(dim=-1, keepdim=True)\n",
        "    text_target_emb = text_target_emb / text_target_emb.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    params_to_optimize = [p for p in generator.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.Adam(params_to_optimize, lr=lr, betas=(0.0, 0.99))\n",
        "\n",
        "    alpha = 0.5\n",
        "\n",
        "    # цикл обучения\n",
        "    pbar = range(steps)\n",
        "    for step_i in pbar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)\n",
        "        generated_imgs, _ = generator([z], truncation=1, input_is_latent=False)\n",
        "\n",
        "        clip_in = clip_preprocess_tensor(generated_imgs)\n",
        "        image_embeds = clip_model.encode_image(clip_in)\n",
        "        image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        target_sim = (image_embeds * text_target_emb).sum(dim=-1)\n",
        "        orig_sim   = (image_embeds * text_orig_emb).sum(dim=-1)\n",
        "\n",
        "        clip_loss = - (target_sim - alpha * orig_sim).mean()\n",
        "        clip_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        yield f\"Шаг {step_i+1}/{steps} | Текущая clip_loss = {clip_loss.item():.4f}\"\n",
        "\n",
        "    final_ckpt_path = os.path.join(outdir, \"stylegan2_nada_final.pt\")\n",
        "    save_checkpoint(generator, final_ckpt_path)\n",
        "\n",
        "    yield f\"Обучение завершено!\\nФинальный чекпоинт сохранён по пути: {final_ckpt_path}\"\n",
        "\n",
        "# функция инференса\n",
        "def infer_model():\n",
        "    final_ckpt_path = os.path.join(outdir, \"stylegan2_nada_final.pt\")\n",
        "    if not os.path.exists(final_ckpt_path):\n",
        "        return [Image.new(\"RGB\", (256, 256), color=(180, 0, 0))]\n",
        "\n",
        "    gen_for_infer = copy_generator(base_generator)\n",
        "    checkpoint = torch.load(final_ckpt_path, map_location=device)\n",
        "    gen_for_infer.load_state_dict(checkpoint[\"g_ema\"], strict=False)\n",
        "    gen_for_infer.eval()\n",
        "\n",
        "    result_images = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(5):\n",
        "            z = torch.randn(1, latent_dim, device=device)\n",
        "            img, _ = gen_for_infer([z], truncation=1, input_is_latent=False)\n",
        "            img = (img.clamp(-1, 1) + 1) / 2\n",
        "            img = (img * 255).permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)[0]\n",
        "            pil_img = Image.fromarray(img)\n",
        "\n",
        "            scale_factor = 1/3\n",
        "            w, h = pil_img.size\n",
        "            new_w, new_h = int(w*scale_factor), int(h*scale_factor)\n",
        "            pil_img_small = pil_img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "            result_images.append(pil_img_small)\n",
        "    return result_images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################\n",
        "# ПРИЛОЖЕНИЕ GRADIO\n",
        "####################\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# App StyleGAN-NADA by AK_12\")\n",
        "\n",
        "    gr.Image(\n",
        "        value=\"/content/Article-implementation-StyleGAN-NADA/DALL·E-hum-joker.png\",\n",
        "        interactive=False,\n",
        "        width=512,\n",
        "        height=512\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"Обучение\"):\n",
        "        gr.Markdown(\"Параметры обучения:\")\n",
        "        freeze_slider   = gr.Slider(minimum=0, maximum=5, step=1, value=1, label=\"freeze_until\")\n",
        "        steps_slider    = gr.Slider(minimum=100, maximum=2000, step=50, value=500, label=\"steps\")\n",
        "        batch_slider    = gr.Slider(minimum=1, maximum=8, step=1, value=2, label=\"batch_size\")\n",
        "        lr_number       = gr.Number(value=1e-4, label=\"learning rate (lr)\")\n",
        "        prompt_target_t = gr.Textbox(value=\"joker\", label=\"prompt_target\")\n",
        "\n",
        "        train_btn = gr.Button(\"Запустить обучение\")\n",
        "        train_output = gr.Textbox(label=\"Лог обучения\")\n",
        "\n",
        "        train_btn.click(\n",
        "            fn=train_model,\n",
        "            inputs=[freeze_slider, steps_slider, batch_slider, lr_number, prompt_target_t],\n",
        "            outputs=train_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Инференс\"):\n",
        "        gr.Markdown(\"Генерация 5 изображений с обученной моделью по промту\")\n",
        "        infer_btn = gr.Button(\"Генерировать\")\n",
        "        gallery = gr.Gallery(label=\"Сгенерированные изображения\", show_label=False).style(grid=[5], height=\"auto\")\n",
        "\n",
        "        infer_btn.click(\n",
        "            fn=infer_model,\n",
        "            inputs=[],\n",
        "            outputs=gallery\n",
        "        )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S4e-siwDok3Z",
        "outputId": "1c162ce7-b48b-4f0c-e5e7-10d3032abcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 26 18:07:49 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  ninja-build\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 111 kB of archives.\n",
            "After this operation, 358 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ninja-build amd64 1.10.1-1 [111 kB]\n",
            "Fetched 111 kB in 1s (147 kB/s)\n",
            "Selecting previously unselected package ninja-build.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../ninja-build_1.10.1-1_amd64.deb ...\n",
            "Unpacking ninja-build (1.10.1-1) ...\n",
            "Setting up ninja-build (1.10.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-1_hgbd5p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-1_hgbd5p\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=88595008f3533eb6422366c8737f9f4f6cc4a2b614e4c39f5e04c95ec736b0cd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fm9sj3yo/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n",
            "Collecting gradio==3.39.0\n",
            "  Downloading gradio-3.39.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.39.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (3.11.10)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (5.5.0)\n",
            "Collecting fastapi (from gradio==3.39.0)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.39.0)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client>=0.3.0 (from gradio==3.39.0)\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (3.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.39.0) (3.0.0)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.39.0)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (3.8.0)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.39.0)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (2.2.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.39.0)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (2.10.3)\n",
            "Collecting pydub (from gradio==3.39.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.39.0)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (6.0.2)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (2.32.3)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.39.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.39.0) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.39.0)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.39.0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.39.0) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.39.0) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.39.0) (1.18.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.3.0->gradio==3.39.0) (2024.10.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.39.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.39.0) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.39.0) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.39.0) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio==3.39.0) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.39.0) (3.16.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.39.0) (4.67.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.39.0) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.39.0) (2.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.39.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.39.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.39.0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.39.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.39.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.39.0) (2.8.2)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.39.0)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.39.0)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.39.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.39.0) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.39.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.39.0) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.39.0) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.39.0) (2.2.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.39.0) (8.1.7)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi->gradio==3.39.0)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.39.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.39.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.39.0) (0.22.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.39.0) (1.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.39.0) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.39.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.39.0) (1.2.2)\n",
            "Downloading gradio-3.39.0-py3-none-any.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, semantic-version, python-multipart, pillow, markupsafe, markdown-it-py, ffmpy, aiofiles, starlette, mdit-py-plugins, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.1\n",
            "    Uninstalling websockets-14.1:\n",
            "      Successfully uninstalled websockets-14.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.2\n",
            "    Uninstalling mdit-py-plugins-0.4.2:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 0.3.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.7 ffmpy-0.5.0 gradio-3.39.0 gradio-client-1.6.0 markdown-it-py-2.2.0 markupsafe-2.1.5 mdit-py-plugins-0.3.3 pillow-10.4.0 pydub-0.25.1 python-multipart-0.0.20 semantic-version-2.10.0 starlette-0.45.3 uvicorn-0.34.0 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "4bd7a2bd5cc54ccf8cc11f30391b94ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Article-implementation-StyleGAN-NADA'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 111 (delta 51), reused 30 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (111/111), 14.08 MiB | 14.68 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "--2025-01-26 18:08:22--  https://huggingface.co/akhaliq/OneshotCLIP-stylegan2-ffhq/resolve/main/stylegan2-ffhq-config-f.pt\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/e9/a3/e9a3ec3ca794fe184757f39017bb3836044f5de0c2ff76d7109137c040c4b817/bae494ef77e32a9cd1792a81a3c167692a0e64f6bcd8b06592ff42917e2ed46e?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27stylegan2-ffhq-config-f.pt%3B+filename%3D%22stylegan2-ffhq-config-f.pt%22%3B&Expires=1737918502&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzkxODUwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9lOS9hMy9lOWEzZWMzY2E3OTRmZTE4NDc1N2YzOTAxN2JiMzgzNjA0NGY1ZGUwYzJmZjc2ZDcxMDkxMzdjMDQwYzRiODE3L2JhZTQ5NGVmNzdlMzJhOWNkMTc5MmE4MWEzYzE2NzY5MmEwZTY0ZjZiY2Q4YjA2NTkyZmY0MjkxN2UyZWQ0NmU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=iLsxvAkimm5f%7ERrPXRu4n5naFHMtYwuVu8sjDoT5-vaYbtDAz60JXqKZ-JA9PN7q71VAT0NaHd9nBjNbIoaVlnwXknkloA52tHjoS1TAbX-lX1ah5bIj-yN2LJpzX2-fIXMh5e-8Hxz5qNdzcManw7x8T4242xAjFvpcYnm6nBlE-UiSbDExOIdm00eqiV4llQHEHmzPOmKhRBqVaw%7Em7KORIfcLaWUV3bqFAx%7EzULZIwU6MqylAkESg3vp5PsgRZb%7EMjCiSvExPQTSWn2H%7Eb0UQeX4q61-i8qDsyQoKs0GhboHYGyElW2XbeU8HghrKo3skFHlZ1bQlHxZVV3SQ%7Eg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-01-26 18:08:22--  https://cdn-lfs.hf.co/repos/e9/a3/e9a3ec3ca794fe184757f39017bb3836044f5de0c2ff76d7109137c040c4b817/bae494ef77e32a9cd1792a81a3c167692a0e64f6bcd8b06592ff42917e2ed46e?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27stylegan2-ffhq-config-f.pt%3B+filename%3D%22stylegan2-ffhq-config-f.pt%22%3B&Expires=1737918502&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNzkxODUwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9lOS9hMy9lOWEzZWMzY2E3OTRmZTE4NDc1N2YzOTAxN2JiMzgzNjA0NGY1ZGUwYzJmZjc2ZDcxMDkxMzdjMDQwYzRiODE3L2JhZTQ5NGVmNzdlMzJhOWNkMTc5MmE4MWEzYzE2NzY5MmEwZTY0ZjZiY2Q4YjA2NTkyZmY0MjkxN2UyZWQ0NmU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=iLsxvAkimm5f%7ERrPXRu4n5naFHMtYwuVu8sjDoT5-vaYbtDAz60JXqKZ-JA9PN7q71VAT0NaHd9nBjNbIoaVlnwXknkloA52tHjoS1TAbX-lX1ah5bIj-yN2LJpzX2-fIXMh5e-8Hxz5qNdzcManw7x8T4242xAjFvpcYnm6nBlE-UiSbDExOIdm00eqiV4llQHEHmzPOmKhRBqVaw%7Em7KORIfcLaWUV3bqFAx%7EzULZIwU6MqylAkESg3vp5PsgRZb%7EMjCiSvExPQTSWn2H%7Eb0UQeX4q61-i8qDsyQoKs0GhboHYGyElW2XbeU8HghrKo3skFHlZ1bQlHxZVV3SQ%7Eg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.168.132.99, 3.168.132.48, 3.168.132.51, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.168.132.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381462551 (364M) [binary/octet-stream]\n",
            "Saving to: ‘stylegan2-ffhq-config-f.pt’\n",
            "\n",
            "stylegan2-ffhq-conf 100%[===================>] 363.79M   180MB/s    in 2.0s    \n",
            "\n",
            "2025-01-26 18:08:25 (180 MB/s) - ‘stylegan2-ffhq-config-f.pt’ saved [381462551/381462551]\n",
            "\n",
            "/content/Article-implementation-StyleGAN-NADA\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n",
            "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
            "/usr/local/lib/python3.10/dist-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n",
            "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
            "100%|███████████████████████████████████████| 338M/338M [00:07<00:00, 45.9MiB/s]\n",
            "<ipython-input-1-76e8b8d77206>:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(ckpt_path_base, map_location=device)\n",
            "<ipython-input-1-76e8b8d77206>:227: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  gallery = gr.Gallery(label=\"Сгенерированные изображения\", show_label=False).style(grid=[5], height=\"auto\")\n",
            "<ipython-input-1-76e8b8d77206>:227: GradioDeprecationWarning: The 'grid' parameter will be deprecated. Please use 'grid_cols' in the constructor instead.\n",
            "  gallery = gr.Gallery(label=\"Сгенерированные изображения\", show_label=False).style(grid=[5], height=\"auto\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.39.0, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://5376c5b93aea612a39.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5376c5b93aea612a39.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Article-implementation-StyleGAN-NADA/op/conv2d_gradfix.py:88: UserWarning: conv2d_gradfix not supported on PyTorch 2.5.1+cu121. Falling back to torch.nn.functional.conv2d().\n",
            "  warnings.warn(\n",
            "<ipython-input-1-76e8b8d77206>:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(final_ckpt_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5376c5b93aea612a39.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "\n",
        "def invert_image(img: Image.Image, generator, steps=300, lr=0.01):\n",
        "    generator.eval()\n",
        "\n",
        "    img_t = torch.from_numpy(np.array(img)).float().to(device) / 255.0\n",
        "    if len(img_t.shape) == 3:\n",
        "        img_t = img_t.permute(2, 0, 1).unsqueeze(0)\n",
        "    img_t = img_t * 2 - 1\n",
        "    img_t = F.interpolate(img_t, size=(1024, 1024), mode='bilinear', align_corners=False)\n",
        "\n",
        "    z_opt = torch.randn(1, latent_dim, device=device, requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.Adam([z_opt], lr=lr)\n",
        "\n",
        "    for step in range(steps):\n",
        "        optimizer.zero_grad()\n",
        "        gen_img, _ = generator([z_opt], truncation=1, input_is_latent=False)\n",
        "\n",
        "        loss = F.mse_loss(gen_img, img_t)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return z_opt.detach()\n",
        "\n",
        "\n",
        "def transform_image(input_img: Image.Image):\n",
        "    try:\n",
        "        outdir = \"/content/outputs_nada_colab\"\n",
        "        final_ckpt_path = os.path.join(outdir, \"stylegan2_nada_final.pt\")\n",
        "        if not os.path.exists(final_ckpt_path):\n",
        "            return Image.new(\"RGB\", (256, 256), color=(255, 0, 0))\n",
        "\n",
        "        gen_for_infer = copy_generator(base_generator)\n",
        "        checkpoint = torch.load(final_ckpt_path, map_location=device)\n",
        "        gen_for_infer.load_state_dict(checkpoint[\"g_ema\"], strict=False)\n",
        "        gen_for_infer.to(device).eval()\n",
        "\n",
        "        z_approx = invert_image(input_img, gen_for_infer, steps=300, lr=0.01)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            gen_img, _ = gen_for_infer([z_approx], truncation=1, input_is_latent=False)\n",
        "\n",
        "        gen_img = (gen_img.clamp(-1, 1) + 1) * 0.5\n",
        "        gen_img = gen_img.mul(255).byte().permute(0, 2, 3, 1).cpu().numpy()\n",
        "        pil_img = Image.fromarray(gen_img[0], 'RGB')\n",
        "\n",
        "        scale_factor = 1/4\n",
        "        w, h = pil_img.size\n",
        "        pil_img_small = pil_img.resize((int(w*scale_factor), int(h*scale_factor)), Image.LANCZOS)\n",
        "\n",
        "        return pil_img_small\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Ошибка внутри transform_image:\", str(e))\n",
        "        raise e\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# App StyleGAN-NADA by AK_12\")\n",
        "\n",
        "    gr.Image(\n",
        "        value=\"/content/Article-implementation-StyleGAN-NADA/DALL·E-hum-joker.png\",\n",
        "        interactive=False,\n",
        "        label=\"Пример изображения\",\n",
        "        width=256,\n",
        "        height=256\n",
        "    )\n",
        "\n",
        "    with gr.Tab(\"Обучение\"):\n",
        "        gr.Markdown(\"Параметры обучения:\")\n",
        "        freeze_slider   = gr.Slider(minimum=0, maximum=5, step=1, value=1, label=\"freeze_until\")\n",
        "        steps_slider    = gr.Slider(minimum=100, maximum=2000, step=50, value=500, label=\"steps\")\n",
        "        batch_slider    = gr.Slider(minimum=1, maximum=8, step=1, value=2, label=\"batch_size\")\n",
        "        lr_number       = gr.Number(value=1e-4, label=\"learning rate (lr)\")\n",
        "        prompt_target_t = gr.Textbox(value=\"joker\", label=\"prompt_target\")\n",
        "\n",
        "        train_btn = gr.Button(\"Запустить обучение\")\n",
        "        train_output = gr.Textbox(label=\"Лог обучения\")\n",
        "\n",
        "        train_btn.click(\n",
        "            fn=train_model,\n",
        "            inputs=[freeze_slider, steps_slider, batch_slider, lr_number, prompt_target_t],\n",
        "            outputs=train_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Инференс\"):\n",
        "        gr.Markdown(\"Генерация 5 изображений с обученной моделью по промту\")\n",
        "        infer_btn = gr.Button(\"Генерировать\")\n",
        "        gallery = gr.Gallery(label=\"Сгенерированные изображения\", show_label=False).style(grid=[5], height=\"auto\")\n",
        "\n",
        "        infer_btn.click(\n",
        "            fn=infer_model,\n",
        "            inputs=[],\n",
        "            outputs=gallery\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Image2Image\"):\n",
        "        gr.Markdown(\"Загрузите свою картинку, и модель попытается её стилизовать.\")\n",
        "        input_image = gr.Image(label=\"Ваше изображение\")\n",
        "        stylize_btn = gr.Button(\"Stylize\")\n",
        "        output_image = gr.Image(label=\"Результат\", interactive=False)\n",
        "\n",
        "        stylize_btn.click(\n",
        "            fn=transform_image,\n",
        "            inputs=[input_image],\n",
        "            outputs=[output_image]\n",
        "        )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "id": "R_QcozvU2CeZ",
        "outputId": "351f02c0-d367-4dca-9068-3412972fec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ace462e06599>:141: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  gallery = gr.Gallery(label=\"Сгенерированные изображения\", show_label=False).style(grid=[5], height=\"auto\")\n",
            "<ipython-input-3-ace462e06599>:141: GradioDeprecationWarning: The 'grid' parameter will be deprecated. Please use 'grid_cols' in the constructor instead.\n",
            "  gallery = gr.Gallery(label=\"Сгенерированные изображения\", show_label=False).style(grid=[5], height=\"auto\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.39.0, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://499126ce8ce6b70935.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://499126ce8ce6b70935.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ace462e06599>:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(final_ckpt_path, map_location=device)\n",
            "/content/Article-implementation-StyleGAN-NADA/op/conv2d_gradfix.py:88: UserWarning: conv2d_gradfix not supported on PyTorch 2.5.1+cu121. Falling back to torch.nn.functional.conv2d().\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://499126ce8ce6b70935.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}